{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d37fec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-Sklearn cannot be imported.\n"
     ]
    }
   ],
   "source": [
    "from Initialize_and_Train import initialize_and_train\n",
    "from generate_knapsack_data import Gen_Knapsack_data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dda79988",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['DYS', 'SPO+']# , 'BBOpt'] #, 'PertOpt', 'PertOpt-FY']\n",
    "item_values = np.arange(30,60,5)\n",
    "num_repeats = 1\n",
    "results_test_loss = np.zeros((len(models), len(item_values), num_repeats))\n",
    "results_train_time = np.zeros((len(models), len(item_values), num_repeats))\n",
    "results_time_till_val_loss = np.zeros((len(models), len(item_values), num_repeats))\n",
    "\n",
    "# hard code some data parameters\n",
    "num_knapsack = 2\n",
    "num_feat = 5\n",
    "num_data = 1100\n",
    "\n",
    "# max values\n",
    "max_epochs = 10\n",
    "# max time hardcoded to 1 hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fb14fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training data for knapsack problem with 2 knapsacks and 30 items\n",
      "Restricted license - for non-production use only - expires 2024-10-28\n",
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 900/900 [00:01<00:00, 513.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 424.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for optDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 449.94it/s]\n",
      "/Users/danielmckenzie/My-Drive/Research/Fixed_Point_Networks/Diff-Opt-Over-Polytopes-Project/SPO_with_DYS/source/Knapsack/dYS_opt_net.py:29: UserWarning: The operator 'aten::linalg_svd' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  U, s, VT = torch.linalg.svd(self.A, full_matrices=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished building dataset\n",
      "\n",
      " Currently training DYS\n",
      "\n",
      "Initial validation loss is  0.42427703738212585\n",
      "epoch:  1 validation loss is  0.0577295646071434 epoch time:  1.3463129997253418\n",
      "epoch:  2 validation loss is  0.04881828650832176 epoch time:  1.1927659511566162\n",
      "epoch:  3 validation loss is  0.04339403286576271 epoch time:  1.2028729915618896\n",
      "epoch:  4 validation loss is  0.04881828650832176 epoch time:  1.1752269268035889\n",
      "epoch:  5 validation loss is  0.04300658777356148 epoch time:  1.2166049480438232\n",
      "epoch:  6 validation loss is  0.04339403286576271 epoch time:  1.1803219318389893\n",
      "epoch:  7 validation loss is  0.046106159687042236 epoch time:  1.1807036399841309\n",
      "epoch:  8 validation loss is  0.05346764996647835 epoch time:  1.1449122428894043\n",
      "epoch:  9 validation loss is  0.05540487915277481 epoch time:  1.1609137058258057\n",
      "epoch:  10 validation loss is  0.05656721815466881 epoch time:  1.0732851028442383\n",
      "\n",
      " Currently training SPO+\n",
      "\n",
      "Num of cores: 1\n",
      "Initial validation loss is  0.42427703738212585\n",
      "epoch:  1 validation loss is  0.06044168770313263 epoch time:  0.38654208183288574\n",
      "epoch:  2 validation loss is  0.03758233040571213 epoch time:  0.501082181930542\n",
      "epoch:  3 validation loss is  0.020147228613495827 epoch time:  0.9055240154266357\n",
      "epoch:  4 validation loss is  0.019759783521294594 epoch time:  0.7245378494262695\n",
      "epoch:  5 validation loss is  0.017822548747062683 epoch time:  0.48479700088500977\n",
      "epoch:  6 validation loss is  0.014335528947412968 epoch time:  0.43363118171691895\n",
      "epoch:  7 validation loss is  0.013948081992566586 epoch time:  0.44727087020874023\n",
      "epoch:  8 validation loss is  0.013173189014196396 epoch time:  0.4445381164550781\n",
      "epoch:  9 validation loss is  0.009686168283224106 epoch time:  0.42089414596557617\n",
      "epoch:  10 validation loss is  0.010073614306747913 epoch time:  0.41423583030700684\n",
      "\n",
      " Currently training BBOpt\n",
      "\n",
      "Num of cores: 1\n",
      "Initial validation loss is  0.42427703738212585\n",
      "epoch:  1 validation loss is  0.2510654926300049 epoch time:  1.427422046661377\n",
      "epoch:  2 validation loss is  0.19914761185646057 epoch time:  1.8029561042785645\n",
      "epoch:  3 validation loss is  0.15342889726161957 epoch time:  2.1163299083709717\n",
      "epoch:  4 validation loss is  0.0720650851726532 epoch time:  2.2883589267730713\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m knapsack_dict \u001b[38;5;241m=\u001b[39m Gen_Knapsack_data(num_data, num_feat, num_item, num_knapsack)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_counter, model_type \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(models):\n\u001b[0;32m---> 13\u001b[0m     train_time, best_test_loss, time_till_best_test_loss \u001b[38;5;241m=\u001b[39m \u001b[43minitialize_and_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mknapsack_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknapsack_data_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     results_test_loss[model_counter, item_counter, repeat] \u001b[38;5;241m=\u001b[39m best_test_loss\n\u001b[1;32m     15\u001b[0m     results_train_time[model_counter, item_counter, repeat] \u001b[38;5;241m=\u001b[39m train_time\n",
      "File \u001b[0;32m~/My-Drive/Research/Fixed_Point_Networks/Diff-Opt-Over-Polytopes-Project/SPO_with_DYS/source/Knapsack/Initialize_and_Train.py:44\u001b[0m, in \u001b[0;36minitialize_and_train\u001b[0;34m(knapsack_dict, knapsack_data_dict, model_type, max_epochs, learning_rate, device)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#if model_type == \"Two-stage\":\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m#    max_epochs = 2*max_epochs\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Currently training \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m model_type \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m test_loss_hist, epoch_time_hist, best_test_loss, time_till_best_test_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_item\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_knapsack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(epoch_time_hist), best_test_loss, time_till_best_test_loss\n",
      "File \u001b[0;32m~/My-Drive/Research/Fixed_Point_Networks/Diff-Opt-Over-Polytopes-Project/SPO_with_DYS/source/Knapsack/Trainer.py:147\u001b[0m, in \u001b[0;36mtrainer\u001b[0;34m(net, train_dataset, test_dataset, val_dataset, num_item, num_knapsack, max_epochs, learning_rate, model_type, device)\u001b[0m\n\u001b[1;32m    144\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(net\u001b[38;5;241m.\u001b[39mstate_dict(), state_save_name)\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# If we have achieved lowest validation thus far, this will be the model selected.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# So, we compute test loss\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m     best_test_loss \u001b[38;5;241m=\u001b[39m \u001b[43mCompute_Test_Loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloader_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_knapsack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_item\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m     time_till_best_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(epoch_time_hist)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# scheduler.step(val_loss)\u001b[39;00m\n",
      "File \u001b[0;32m~/My-Drive/Research/Fixed_Point_Networks/Diff-Opt-Over-Polytopes-Project/SPO_with_DYS/source/Knapsack/knapsack_utils.py:34\u001b[0m, in \u001b[0;36mCompute_Test_Loss\u001b[0;34m(net, loader, model_type, metric, num_knapsack, num_item, device)\u001b[0m\n\u001b[1;32m     32\u001b[0m opt_sol \u001b[38;5;241m=\u001b[39m opt_sol\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     33\u001b[0m opt_value \u001b[38;5;241m=\u001b[39m opt_value\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 34\u001b[0m predicted \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDYS\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     36\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m metric(w_batch, predicted[:,:\u001b[38;5;241m-\u001b[39m(num_knapsack \u001b[38;5;241m+\u001b[39m num_item)], opt_sol, opt_value, eval_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/My-Drive/Research/Fixed_Point_Networks/Diff-Opt-Over-Polytopes-Project/SPO_with_DYS/source/Knapsack/ModelsKnapSack.py:130\u001b[0m, in \u001b[0;36mValPredictNet.forward\u001b[0;34m(self, d)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mknapsack_solver\u001b[38;5;241m.\u001b[39msetObj(w[i,:])\n\u001b[1;32m    129\u001b[0m     solution, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mknapsack_solver\u001b[38;5;241m.\u001b[39msolve()\n\u001b[0;32m--> 130\u001b[0m     solutions[i,:] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msolution\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m solutions\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for item_counter, num_item in enumerate(item_values):\n",
    "    knapsack_data_dict = {'num_knapsack': num_knapsack,\n",
    "                          'num_item': num_item,\n",
    "                          'num_feat': num_feat,\n",
    "                          'num_data': num_data\n",
    "                         } \n",
    "    \n",
    "    # Do the thing\n",
    "    for repeat in range(num_repeats):\n",
    "        # Generate Data\n",
    "        knapsack_dict = Gen_Knapsack_data(num_data, num_feat, num_item, num_knapsack)\n",
    "        for model_counter, model_type in enumerate(models):\n",
    "            train_time, best_test_loss, time_till_best_test_loss = initialize_and_train(knapsack_dict, knapsack_data_dict, model_type, max_epochs)\n",
    "            results_test_loss[model_counter, item_counter, repeat] = best_test_loss\n",
    "            results_train_time[model_counter, item_counter, repeat] = train_time\n",
    "            results_time_till_val_loss[model_counter, item_counter, repeat] = time_till_best_test_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d3e6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f40dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a93c416",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test_loss_mean = np.mean(results_test_loss, axis=2)\n",
    "print(results_test_loss_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00be30e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for idx, model_type in enumerate(models):\n",
    "    plt.plot(item_values, results_test_loss_mean[idx,:], label=model_type)\n",
    "\n",
    "plt.title(\"Best Regret Achieved\")\n",
    "plt.legend()\n",
    "plt.savefig('Knapsack_experiment_varying_num_items_regret_55.pdf')\n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333c9f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_time_till_val_loss_mean = np.mean(results_time_till_val_loss, axis=2)\n",
    "print(results_time_till_val_loss_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145d2f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, model_type in enumerate(models):\n",
    "    print(idx, model_type)\n",
    "    plt.plot(item_values, results_time_till_val_loss_mean[idx,:], label=model_type)\n",
    "\n",
    "plt.title(\"Train Time\")\n",
    "plt.legend()\n",
    "plt.savefig('Knapsack_experiment_varying_num_items_train_time_55.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bed3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, model_type in enumerate(models):\n",
    "    print(idx, model_type)\n",
    "    plt.plot(item_values, results_time_till_best_loss[idx,:], label=model_type)\n",
    "\n",
    "plt.title(\"Train Time till Best Model\")\n",
    "plt.legend()\n",
    "# plt.savefig('Knapsack_experiment_varying_num_items_train_time.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f136463",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_time_till_best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e883fa84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
