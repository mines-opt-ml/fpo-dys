{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing path length as an accuracy measure\n",
    "\n",
    "Quick notebook to test the validity of this idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./source/') # append files from source folder\n",
    "\n",
    "import torch\n",
    "from GenerateShortestPathData import create_shortest_path_data\n",
    "from ModelsShortestPath import ShortestPathNet, Cvx_ShortestPathNet, Pert_ShortestPathNet, BB_ShortestPathNet\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import Regret\n",
    "import time as time\n",
    "from Trainer import trainer\n",
    "import numpy as np\n",
    "\n",
    "## Set device\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some fixed hyperparameters\n",
    "max_epochs = 100\n",
    "init_lr = 1e-2 # initial learning rate. We're using a scheduler.\n",
    "torch.manual_seed(0)\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some arrays\n",
    "tl_trained_DYS = [] # test loss\n",
    "tt_trained_DYS = [] # training time\n",
    "ta_trained_DYS = [] # test accuracy of trained model\n",
    "ne_trained_DYS = [] # number of epochs completed during training\n",
    "\n",
    "tl_trained_CVX = []\n",
    "tt_trained_CVX = []\n",
    "ta_trained_CVX = []\n",
    "ne_trained_CVX = []\n",
    "\n",
    "tl_trained_PertOpt = []\n",
    "tt_trained_PertOpt = []\n",
    "ta_trained_PertOpt = []\n",
    "ne_trained_PertOpt = []\n",
    "\n",
    "tl_trained_BB = []\n",
    "tt_trained_BB = []\n",
    "ta_trained_BB = []\n",
    "ne_trained_BB = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------- TRAINING PertOpt GRID 5-by-5 --------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 | ave_tr_loss:  5.57e-02 | te_loss:  3.16e-01 | acc.:  0.000000 | lr:  1.00e-02 | regret:  0.274905 | time:  8.167840       \n",
      "epoch:  1 | ave_tr_loss:  9.47e-02 | te_loss:  3.07e-01 | acc.:  0.020000 | lr:  1.00e-02 | regret:  0.113401 | time:  16.907581      \n",
      "epoch:  2 | ave_tr_loss:  1.22e-01 | te_loss:  2.75e-01 | acc.:  0.370000 | lr:  1.00e-02 | regret:  0.037209 | time:  25.595192      \n",
      "epoch:  3 | ave_tr_loss:  1.43e-01 | te_loss:  2.75e-01 | acc.:  0.370000 | lr:  1.00e-02 | regret:  0.037209 | time:  34.205335      \n",
      "epoch:  4 | ave_tr_loss:  1.57e-01 | te_loss:  2.75e-01 | acc.:  0.370000 | lr:  1.00e-02 | regret:  0.037209 | time:  42.789703      \n",
      "epoch:  5 | ave_tr_loss:  1.66e-01 | te_loss:  2.73e-01 | acc.:  0.375000 | lr:  1.00e-02 | regret:  0.036119 | time:  51.348838      \n",
      "epoch:  6 | ave_tr_loss:  1.71e-01 | te_loss:  2.64e-01 | acc.:  0.385000 | lr:  1.00e-02 | regret:  0.032562 | time:  59.883339      \n",
      "epoch:  7 | ave_tr_loss:  1.73e-01 | te_loss:  2.10e-01 | acc.:  0.420000 | lr:  1.00e-02 | regret:  0.022460 | time:  68.442427      \n",
      "epoch:  8 | ave_tr_loss:  1.73e-01 | te_loss:  1.71e-01 | acc.:  0.425000 | lr:  1.00e-02 | regret:  0.018685 | time:  77.026340      \n",
      "epoch:  9 | ave_tr_loss:  1.72e-01 | te_loss:  1.93e-01 | acc.:  0.420000 | lr:  1.00e-02 | regret:  0.020408 | time:  85.651860      \n",
      "epoch:  10 | ave_tr_loss:  1.69e-01 | te_loss:  1.97e-01 | acc.:  0.410000 | lr:  1.00e-02 | regret:  0.020968 | time:  94.422446      \n",
      "epoch:  11 | ave_tr_loss:  1.66e-01 | te_loss:  1.80e-01 | acc.:  0.435000 | lr:  1.00e-02 | regret:  0.018880 | time:  103.062806     \n",
      "epoch:  12 | ave_tr_loss:  1.63e-01 | te_loss:  1.41e-01 | acc.:  0.510000 | lr:  1.00e-02 | regret:  0.014492 | time:  111.670834     \n",
      "epoch:  13 | ave_tr_loss:  1.58e-01 | te_loss:  1.47e-01 | acc.:  0.510000 | lr:  1.00e-02 | regret:  0.014442 | time:  120.302607     \n",
      "epoch:  14 | ave_tr_loss:  1.53e-01 | te_loss:  1.60e-01 | acc.:  0.500000 | lr:  1.00e-02 | regret:  0.015028 | time:  128.937173     \n",
      "epoch:  15 | ave_tr_loss:  1.48e-01 | te_loss:  1.40e-01 | acc.:  0.505000 | lr:  1.00e-02 | regret:  0.014140 | time:  137.588260     \n",
      "epoch:  16 | ave_tr_loss:  1.43e-01 | te_loss:  1.25e-01 | acc.:  0.520000 | lr:  1.00e-02 | regret:  0.013585 | time:  146.252604     \n",
      "epoch:  17 | ave_tr_loss:  1.39e-01 | te_loss:  1.16e-01 | acc.:  0.495000 | lr:  1.00e-02 | regret:  0.013500 | time:  154.860284     \n",
      "epoch:  18 | ave_tr_loss:  1.35e-01 | te_loss:  1.25e-01 | acc.:  0.480000 | lr:  1.00e-02 | regret:  0.013981 | time:  163.524959     \n",
      "epoch:  19 | ave_tr_loss:  1.32e-01 | te_loss:  1.09e-01 | acc.:  0.510000 | lr:  1.00e-02 | regret:  0.013427 | time:  172.763259     \n",
      "epoch:  20 | ave_tr_loss:  1.29e-01 | te_loss:  1.09e-01 | acc.:  0.515000 | lr:  1.00e-02 | regret:  0.013443 | time:  182.019179     \n",
      "epoch:  21 | ave_tr_loss:  1.25e-01 | te_loss:  1.09e-01 | acc.:  0.520000 | lr:  1.00e-02 | regret:  0.013109 | time:  190.640721     \n",
      "epoch:  22 | ave_tr_loss:  1.22e-01 | te_loss:  1.18e-01 | acc.:  0.495000 | lr:  1.00e-02 | regret:  0.013895 | time:  199.187158     \n",
      "epoch:  23 | ave_tr_loss:  1.20e-01 | te_loss:  1.32e-01 | acc.:  0.495000 | lr:  1.00e-02 | regret:  0.015011 | time:  207.884136     \n",
      "epoch:  24 | ave_tr_loss:  1.19e-01 | te_loss:  1.18e-01 | acc.:  0.525000 | lr:  1.00e-02 | regret:  0.014845 | time:  216.412739     \n",
      "epoch:  25 | ave_tr_loss:  1.18e-01 | te_loss:  1.12e-01 | acc.:  0.520000 | lr:  1.00e-02 | regret:  0.014759 | time:  224.952751     \n",
      "epoch:  26 | ave_tr_loss:  1.17e-01 | te_loss:  1.14e-01 | acc.:  0.530000 | lr:  1.00e-02 | regret:  0.013914 | time:  233.506401     \n",
      "epoch:  27 | ave_tr_loss:  1.16e-01 | te_loss:  1.17e-01 | acc.:  0.500000 | lr:  1.00e-02 | regret:  0.013688 | time:  242.127393     \n",
      "epoch:  28 | ave_tr_loss:  1.14e-01 | te_loss:  1.06e-01 | acc.:  0.525000 | lr:  1.00e-02 | regret:  0.013009 | time:  250.762340     \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ea9394b2b1a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n-------------------------------------------- TRAINING PertOpt GRID '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-by-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' --------------------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     tl_PertOpt, tt_PertOpt, ta_PertOpt = trainer(PertOpt_net, train_dataset_v,\n\u001b[0m\u001b[1;32m     52\u001b[0m                                               \u001b[0mtest_dataset_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                                               \u001b[0minit_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'V'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEdge_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEdge_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/Implicit-Networks/SPO_with_DYS/./source/Trainer.py\u001b[0m in \u001b[0;36mtrainer\u001b[0;34m(net, train_dataset, test_dataset, grid_size, WW, max_epochs, learning_rate, graph_type, Edge_list, device, max_time, use_scheduler)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mpath_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mtrain_loss_ave\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.95\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrain_loss_ave\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/Implicit-Networks/SPO_with_DYS/./source/ModelsShortestPath.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, d)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m           \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpert_dijkstra\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m           \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdijkstra\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/Implicit-Networks/SPO_with_DYS/./source/perturbations.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(input_tensor, *args)\u001b[0m\n\u001b[1;32m    199\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_input_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPerturbedFunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/Implicit-Networks/SPO_with_DYS/./source/perturbations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, input_tensor, *args)\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0mperturbed_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperturbed_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_batch_dim_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0;31m# Calls user-defined function in a perturbation agnostic manner.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                 \u001b[0mperturbed_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperturbed_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m                 \u001b[0;31m# [NB, D1, ..., Dk] ->  [N, B, D1, ..., Dk].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0mperturbed_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperturbed_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperturbed_input_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/Implicit-Networks/SPO_with_DYS/./source/torch_Dijkstra.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    106\u001b[0m                       axis=0)\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/Implicit-Networks/SPO_with_DYS/./source/torch_Dijkstra.py\u001b[0m in \u001b[0;36mrun_batch\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     return torch.stack([self.run_single(tensor[i])\n\u001b[0m\u001b[1;32m     99\u001b[0m                      for i in range(tensor.shape[0])],\n\u001b[1;32m    100\u001b[0m                     axis=0)\n",
      "\u001b[0;32m~/Research/Implicit-Networks/SPO_with_DYS/./source/torch_Dijkstra.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     return torch.stack([self.run_single(tensor[i])\n\u001b[0m\u001b[1;32m     99\u001b[0m                      for i in range(tensor.shape[0])],\n\u001b[1;32m    100\u001b[0m                     axis=0)\n",
      "\u001b[0;32m~/Research/Implicit-Networks/SPO_with_DYS/./source/torch_Dijkstra.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, costs, Gen_Data)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheapq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheappop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for grid_size in range(5, 6, 5):\n",
    "    \n",
    "    ## Load data\n",
    "    data_path = './shortest_path_data/Shortest_Path_training_data'+str(grid_size)+'.pth'\n",
    "    state = torch.load(data_path)\n",
    "\n",
    "    ## Extract data from state\n",
    "    train_dataset_e = state['train_dataset_e']\n",
    "    test_dataset_e = state['test_dataset_e']\n",
    "    train_dataset_v = state['train_dataset_v']\n",
    "    test_dataset_v = state['test_dataset_v']\n",
    "    m = state[\"m\"]\n",
    "    A = state[\"A\"].float()\n",
    "    WW = state[\"WW\"].float()\n",
    "    b = state[\"b\"].float()\n",
    "    num_edges = state[\"num_edges\"]\n",
    "    Edge_list = state[\"Edge_list\"]\n",
    "    Edge_list_torch = torch.tensor(Edge_list)\n",
    "    \n",
    "    ## Set device\n",
    "    device = 'cuda:0'\n",
    "    \n",
    "#     ## Load model/network\n",
    "#     DYS_net = ShortestPathNet(A, b, num_vertices = grid_size**2, num_edges = num_edges ,\n",
    "#                       Edges = Edge_list_torch.to(device), context_size = 5)\n",
    "#     DYS_net.to(device)\n",
    "    \n",
    "#     # Train\n",
    "#     tl_DYS, tt_DYS, ta_DYS = trainer(DYS_net, train_dataset_e, test_dataset_e, grid_size, WW, \n",
    "#                                     max_epochs, init_lr, graph_type='E', Edge_list = Edge_list)\n",
    "    \n",
    "    ## Load model/network\n",
    "#     CVX_net = Cvx_ShortestPathNet(A.float(), b.float(), 5)\n",
    "#     CVX_net.to(device)\n",
    "\n",
    "\n",
    "#     # Train\n",
    "#     print('\\n-------------------------------------------- TRAINING CVX GRID ' + str(grid_size) + '-by-' + str(grid_size) + ' --------------------------------------------')\n",
    "#     start_time = time.time()\n",
    "#     tl_CVX, tt_CVX, ta_CVX = trainer(CVX_net, train_dataset_e, test_dataset_e, grid_size, WW,\n",
    "#                             max_epochs, init_lr, graph_type='E', Edge_list = Edge_list, max_time=np.inf)\n",
    "\n",
    "#     end_time = time.time()\n",
    "#     print('\\n time to train CVX GRID ' + str(grid_size) + '-by-' + str(grid_size), ' = ', end_time-start_time, ' seconds')\n",
    "    \n",
    "    ## Load model/network\n",
    "    PertOpt_net = Pert_ShortestPathNet(grid_size, context_size=5, device='cpu') # PertOpt not GPU Compatible\n",
    "    PertOpt_net.to('cpu')\n",
    "\n",
    "    # Train\n",
    "    print('\\n-------------------------------------------- TRAINING PertOpt GRID ' + str(grid_size) + '-by-' + str(grid_size) + ' --------------------------------------------')\n",
    "    start_time = time.time()\n",
    "    tl_PertOpt, tt_PertOpt, ta_PertOpt = trainer(PertOpt_net, train_dataset_v,\n",
    "                                              test_dataset_v, grid_size, WW, max_epochs,\n",
    "                                              init_lr, graph_type='V', Edge_list = Edge_list,\n",
    "                                              device='cpu', max_time=np.inf, use_scheduler=False) # note PertOpt is not GPU compatible\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "device = 'cuda:0'\n",
    "WW = state[\"WW\"].float()\n",
    "WW = WW.to(device)\n",
    "test_loader_e = DataLoader(dataset=test_dataset_e, batch_size=200, shuffle=False)\n",
    "d_batch, path_batch = next(iter(test_loader_e))\n",
    "d_batch = d_batch.to(device)\n",
    "path_batch = path_batch.to(device)\n",
    "pred_batch = DYS_net(d_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(WW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regret = Regret(WW,d_batch, path_batch, pred_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
